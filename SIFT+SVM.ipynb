{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib  # To save and load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Use OpenCV to load images quickly\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, a)\n\u001b[0;32m---> 18\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to grayscale directly\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "classes = 43  # Number of classes in the dataset\n",
    "\n",
    "# Storage\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load images and extract SIFT features\n",
    "for i in range(classes):\n",
    "    path = os.path.join('gtsrb-german-traffic-sign/Train', str(i))\n",
    "    images = os.listdir(path)\n",
    "    \n",
    "    for a in images:\n",
    "        try:\n",
    "            # Use OpenCV to load images quickly\n",
    "            image_path = os.path.join(path, a)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale directly\n",
    "            if image is None:\n",
    "                continue\n",
    "            \n",
    "            image = cv2.resize(image, (10, 10))  # Resize for consistency\n",
    "            \n",
    "            # Extract SIFT features\n",
    "            keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "            if descriptors is not None:\n",
    "                data.append(descriptors.flatten())  # Flatten for SVM\n",
    "                labels.append(i)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {a}: {e}\")\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "data = np.array(data, dtype='object')\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Define number of visual words (clusters)\n",
    "NUM_CLUSTERS = 100  # Lowering to 100 clusters to speed up training\n",
    "\n",
    "# Convert variable-length SIFT descriptors into a single feature vector using K-Means\n",
    "all_descriptors = np.vstack(data)  # Stack all extracted features\n",
    "kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42, n_init=10)\n",
    "kmeans.fit(all_descriptors)\n",
    "\n",
    "# Convert images to histograms of visual words\n",
    "def compute_bovw_features(image_descriptors, kmeans_model, num_clusters=NUM_CLUSTERS):\n",
    "    \"\"\"Convert SIFT descriptors into Bag of Visual Words (BoVW) histograms.\"\"\"\n",
    "    histogram = np.zeros(num_clusters)\n",
    "    if image_descriptors is not None:\n",
    "        cluster_labels = kmeans_model.predict(image_descriptors)  # Assign features to clusters\n",
    "        for label in cluster_labels:\n",
    "            histogram[label] += 1\n",
    "    return histogram\n",
    "\n",
    "# Transform all training images into histograms\n",
    "data_bovw = np.array([compute_bovw_features(desc, kmeans) for desc in data])\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "data_bovw = scaler.fit_transform(data_bovw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_bovw, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Save trained model\n",
    "joblib.dump(svm_model, \"svm_traffic_signs.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "joblib.dump(kmeans, \"kmeans_bovw.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"SVM Model trained and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_sign_svm(image, svm_model, kmeans_model, scaler, label_encoder):\n",
    "    \"\"\"Recognizes traffic signs using SIFT + BoVW + SVM classification.\"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    if descriptors is None:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    # Convert descriptors into a BoVW histogram\n",
    "    bovw_features = compute_bovw_features(descriptors, kmeans_model).reshape(1, -1)\n",
    "    bovw_features = scaler.transform(bovw_features)\n",
    "\n",
    "    # Predict using SVM\n",
    "    predicted_label = svm_model.predict(bovw_features)[0]\n",
    "\n",
    "    # Convert back to sign name\n",
    "    recognized_sign = label_encoder.inverse_transform([predicted_label])[0]\n",
    "    return recognized_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models\n",
    "svm_model = joblib.load(\"svm_traffic_signs.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "kmeans = joblib.load(\"kmeans_bovw.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Test on a new image\n",
    "test_image_path = \"GTSRB/Test/00000.png\"\n",
    "test_image = cv2.imread(test_image_path)\n",
    "test_image = cv2.resize(test_image, (30,30))\n",
    "\n",
    "recognized_sign = recognize_sign_svm(test_image, svm_model, kmeans, scaler, label_encoder)\n",
    "print(f\"Recognized Sign: {recognized_sign}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gis_env)",
   "language": "python",
   "name": "gis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
