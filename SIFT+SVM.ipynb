{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from skimage.feature import hog\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Dataset & Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting HOG Features: 100%|██████████| 39209/39209 [02:18<00:00, 283.15img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded: 39209 images with extracted HOG features.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (64, 64)  # Standardized Image Size\n",
    "\n",
    "def load_data(dataset_path, classes):\n",
    "    \"\"\"Loads dataset, applies preprocessing, and extracts HOG features.\"\"\"\n",
    "    \n",
    "    data, labels = [], []\n",
    "    total_images = sum(len(os.listdir(os.path.join(dataset_path, str(i)))) for i in range(classes))\n",
    "\n",
    "    with tqdm(total=total_images, desc=\"Extracting HOG Features\", unit=\"img\") as pbar:\n",
    "        for i in range(classes):\n",
    "            path = os.path.join(dataset_path, str(i))\n",
    "            images = os.listdir(path)\n",
    "            \n",
    "            for img_name in images:\n",
    "                try:\n",
    "                    img_path = os.path.join(path, img_name)\n",
    "                    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "                    if image is None:\n",
    "                        continue\n",
    "                    \n",
    "                    # Convert image to grayscale\n",
    "                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Resize image\n",
    "                    gray = cv2.resize(gray, IMG_SIZE)\n",
    "\n",
    "                    # Compute HOG Features\n",
    "                    features = hog(gray, pixels_per_cell=(8, 8), cells_per_block=(3, 3), feature_vector=True)\n",
    "                    \n",
    "                    data.append(features)\n",
    "                    labels.append(i)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_name}: {e}\")\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "dataset_path = \"gtsrb-german-traffic-sign/Train\"\n",
    "classes = 43  \n",
    "X, y = load_data(dataset_path, classes)\n",
    "\n",
    "print(f\"Dataset Loaded: {len(X)} images with extracted HOG features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Encode Labels & Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Encoded & Features Standardized.\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Labels Encoded & Features Standardized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Split: 31367 training samples, 7842 testing samples.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Data Split: {len(X_train)} training samples, {len(X_test)} testing samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Train Optimized SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Optimized SVM Model...\")\n",
    "\n",
    "svm_model = SGDClassifier(loss='hinge', max_iter=5000, tol=1e-4, alpha=0.00001, \n",
    "                          learning_rate='adaptive', eta0=0.0005, \n",
    "                          penalty='elasticnet', l1_ratio=0.25, n_jobs=-1)\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Train model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Save Model & Preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(svm_model, \"hog_svm_traffic_signs_fast.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"Model & Preprocessing Files Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Final Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Define Function to Recognize a Traffic Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_sign_hog(image, svm_model, scaler, label_encoder):\n",
    "    \"\"\"Recognizes traffic signs using HOG + SVM classification.\"\"\"\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize image\n",
    "    gray = cv2.resize(gray, IMG_SIZE)\n",
    "\n",
    "    # Apply augmentation for testing\n",
    "    transform = A.Compose([\n",
    "        A.RandomBrightnessContrast(p=0.3),\n",
    "        A.Rotate(limit=15, p=0.5),\n",
    "    ])\n",
    "    augmented = transform(image=gray)[\"image\"]\n",
    "\n",
    "    # Extract HOG Features\n",
    "    features = hog(augmented, pixels_per_cell=(8, 8), cells_per_block=(3, 3), feature_vector=True)\n",
    "    features = scaler.transform([features])\n",
    "\n",
    "    # Predict with SVM\n",
    "    predicted_label = svm_model.predict(features)[0]\n",
    "    recognized_sign = label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "    return recognized_sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Test Model on a New Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = joblib.load(\"hog_svm_traffic_signs_fast.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "test_image_path = \"gtsrb-german-traffic-sign/Test/00000.png\"\n",
    "test_image = cv2.imread(test_image_path)\n",
    "\n",
    "if test_image is not None:\n",
    "    recognized_sign = recognize_sign_hog(test_image, svm_model, scaler, label_encoder)\n",
    "    print(f\"Recognized Sign: {recognized_sign}\")\n",
    "else:\n",
    "    print(\"Test Image Not Found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
